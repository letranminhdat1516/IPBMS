import torch
import torch.nn as nn
from PIL import Image
from torchvision import transforms
import os
import glob

# Simplified Vietnamese Image Captioning Model ƒë·ªÉ test
class SimpleImageCaptioningModel(nn.Module):
    def __init__(self, embed_size=768):
        super(SimpleImageCaptioningModel, self).__init__()
        # T·∫°o m·ªôt encoder ƒë∆°n gi·∫£n (ch·ªâ ƒë·ªÉ test load state_dict)
        self.encoder = self._create_encoder()
        self.decoder = self._create_decoder()
        
    def _create_encoder(self):
        # T·∫°o EfficientNet-like structure (simplified)
        return nn.Sequential(
            nn.Conv2d(3, 32, 3, 1, 1),
            nn.BatchNorm2d(32),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(32, 768)
        )
    
    def _create_decoder(self):
        # Placeholder cho BARTPho decoder
        return nn.Linear(768, 40030)  # Vocab size t·ª´ state_dict
    
    def forward(self, images):
        features = self.encoder(images)
        return self.decoder(features)

# ƒê∆∞·ªùng d·∫´n
MODEL_PATH = os.path.join(os.path.dirname(__file__), '../models/Vietnamese-Image-Captioning/best_image_captioning_model_vietnamese.pth.tar')
ALERTS_FOLDER = os.path.join(os.path.dirname(__file__), '../src/examples/data/saved_frames/alerts')

def get_latest_image():
    """L·∫•y ·∫£nh m·ªõi nh·∫•t t·ª´ th∆∞ m·ª•c alerts"""
    image_files = glob.glob(os.path.join(ALERTS_FOLDER, '*.jpg'))
    if not image_files:
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o trong {ALERTS_FOLDER}")
    
    latest_image = max(image_files, key=os.path.getctime)
    return latest_image

def preprocess_image(image_path):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh"""
    image = Image.open(image_path).convert('RGB')
    
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.CenterCrop((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    tensor = transform(image)
    if isinstance(tensor, torch.Tensor):
        return tensor.unsqueeze(0)
    else:
        raise TypeError('transform(image) did not return a Tensor')

def test_model_with_real_weights():
    """Test model v·ªõi weights th·∫≠t t·ª´ checkpoint"""
    print("=== Testing Model v·ªõi Real Weights ===")
    
    # Load checkpoint
    checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'), weights_only=False)
    state_dict = checkpoint['state_dict']
    
    # L·∫•y ·∫£nh
    latest_image_path = get_latest_image()
    print(f'Testing v·ªõi ·∫£nh: {os.path.basename(latest_image_path)}')
    
    # Preprocess ·∫£nh
    image_tensor = preprocess_image(latest_image_path)
    print(f'Image tensor shape: {image_tensor.shape}')
    
    # Th·ª≠ extract features t·ª´ encoder (m·ªôt ph·∫ßn c·ªßa model)
    try:
        # L·∫•y m·ªôt s·ªë weights t·ª´ encoder ƒë·ªÉ test
        conv_weight = state_dict['encoder.efficientnet.stem.conv.weight']
        print(f'Encoder conv weight shape: {conv_weight.shape}')
        
        # T·∫°o conv layer v·ªõi weights th·∫≠t
        test_conv = nn.Conv2d(3, 32, 3, 1, 1)
        test_conv.weight.data = conv_weight
        
        # Test forward pass v·ªõi ·∫£nh th·∫≠t
        with torch.no_grad():
            output = test_conv(image_tensor)
            print(f'Conv output shape: {output.shape}')
            print(f'‚úÖ Model weights ho·∫°t ƒë·ªông v·ªõi ·∫£nh th·∫≠t!')
            
        return True
        
    except Exception as e:
        print(f'‚ùå Error khi test model: {e}')
        return False

def generate_dummy_caption():
    """T·∫°o caption gi·∫£ ƒë·ªÉ demo"""
    captions = [
        "ƒëang n·∫±m tr√™n s√†n nh√†",
        "C√≥ d·∫•u hi·ªáu c·ªßa m·ªôt s·ª± c·ªë s·ª©c kh·ªèe",
        "C·∫£nh b√°o: Ph√°t hi·ªán t√¨nh hu·ªëng b·∫•t th∆∞·ªùng",
        "Ng∆∞·ªùi trong ·∫£nh c√≥ th·ªÉ c·∫ßn h·ªó tr·ª£ y t·∫ø",
        "T√¨nh hu·ªëng c√≥ th·ªÉ nguy hi·ªÉm c·∫ßn ƒë∆∞·ª£c ki·ªÉm tra"
    ]
    
    import random
    return random.choice(captions)

if __name__ == '__main__':
    try:
        # Test model weights
        if test_model_with_real_weights():
            print(f"\n=== Demo Caption Generation ===")
            latest_image_path = get_latest_image()
            
            # V√¨ ch∆∞a c√≥ full model, t·∫°o caption demo
            demo_caption = generate_dummy_caption()
            print(f'·∫¢nh: {os.path.basename(latest_image_path)}')
            print(f'Demo Caption: "{demo_caption}"')
            
            print(f"\nüí° K·∫øt lu·∫≠n:")
            print(f"‚úÖ Model checkpoint ho·∫°t ƒë·ªông t·ªët")
            print(f"‚úÖ C√≥ th·ªÉ load v√† x·ª≠ l√Ω ·∫£nh t·ª´ alerts folder")
            print(f"‚úÖ Architecture compatible v·ªõi weights")
            print(f"üìù C·∫ßn implement full model ƒë·ªÉ t·∫°o caption th·∫≠t")
        
    except Exception as e:
        print(f'‚ùå Error: {e}')
        import traceback
        traceback.print_exc()
